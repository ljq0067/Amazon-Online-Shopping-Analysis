---
title: "Clustering"
author: "Jieqian Liu"
date: "10/12/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(stats)
library(NbClust)
library(cluster)
library(mclust)
library(amap)  
library(factoextra) 
library(purrr)
library(stylo) 
library(philentropy)
library(SnowballC)
library(caTools)
library(dplyr)
library(textstem)
library(stringr)
library(wordcloud)
library(tm)
library(tidyr)
```

## reading in data 
```{r cars}
data <- read.csv('Stanford_MSA_Database.csv')
title <- data[2]
dataNum <- subset(data, select = -c(3:7))
dataNum <- subset(dataNum, select = -c(9:14))
dataNum <- subset(dataNum, select = -c(11:14))
dataNum <- subset(dataNum, select = -c(17:40))
dataNum <- subset(dataNum, select = -c(1))
```

## cleaning 
```{r}
label <- dataNum$Title
indx <- sapply(dataNum, is.factor)
dataNum[indx] <- lapply(dataNum[indx], function(x) as.integer(x))

finalData <- cbind(dataNum, dataNum[indx])
finalData <- subset(finalData, select = -c(16:25))
finalData <- cbind(label, finalData)
finalData <- subset(finalData, select = -c(2))
write.csv(finalData, 'kmeansR.csv')
```

## removing label from dataset
```{r}
# removing label from dataset to preform clustering 
finalData <- finalData[ ,-c(1) ]
```


## normalizing data 
```{r}
normDataNum <- as.data.frame(apply(finalData[,1:14], 2,
                                 function(x) (x - min(x))/(max(x)-min(x))))
```

## Determining optimal K
```{r}
#initial elbow method
kmeansElbow <-NbClust::NbClust(normDataNum,min.nc=2, max.nc=5, method="kmeans")
```

## Viz of Optimal K
```{r}
# barplot of optimal k
table(kmeansElbow$Best.n[1,])

barplot(table(kmeansElbow$Best.n[1,]), 
        xlab="Numer of Clusters", ylab="",
        main="Number of Clusters")

# silhouette of optimal k
fviz_nbclust(normDataNum, method = "silhouette", FUN = hcut, k.max = 5)

# improved elbow plot of optimal k
fviz_nbclust(
  as.matrix(normDataNum), 
  kmeans, 
  k.max = 5,
  method = "wss",
  diss = get_dist(as.matrix(normDataNum), method = "manhattan")
)
```

## K Means Clustering

## K means K = 2
```{r}
clusterResult <- kmeans(normDataNum, 2, nstart=25) 

fviz_cluster(clusterResult, normDataNum, main="Euclidean")
```

## K means K = 3
```{r}
clusterResult <- kmeans(normDataNum, 3, nstart=25) 

fviz_cluster(clusterResult, normDataNum, main="Euclidean")
```

## K means K = 4
```{r}
clusterResult <- kmeans(normDataNum, 4, nstart=25) 

fviz_cluster(clusterResult, normDataNum, main="Euclidean")
```

## Calculating Hierarchical Clusters and Visualizing via dendrogram
```{r}
manhatDist <- stats::dist(normDataNum, method="manhattan")
hierarcClust <- hclust(manhatDist, method="ward.D2")
plot(hierarcClust, cex=.7, hang=-30,main = "Manhattan")
rect.hclust(hierarcClust, k=2)
```

```{r}
euclidDist<- dist(finalData, method = "euclidean")

fviz_dist(euclidDist, gradient = list(low = "#00AFBB", 
                            mid = "white", high = "#FC4E07"))+
                            ggtitle("Euclidean Heatmap")

manhatDist<- dist(finalData, method = "minkowski", p=1)
fviz_dist(manhatDist, gradient = list(low = "#00AFBB", 
                            mid = "white", high = "#FC4E07"))+
                            ggtitle("Manhattan Heatmap")

matrixCos <- (as.matrix(scale(t(finalData))))
cosDist = 1-crossprod(matrixCos) /(sqrt(colSums(matrixCos^2)%*%t(colSums(matrixCos^2))))

finalCosDist <- as.dist(cosDist)
fviz_dist(finalCosDist, gradient = list(low = "#00AFBB", 
                            mid = "white", high = "#FC4E07"))+
                            ggtitle("Cosine Heatmap")
```